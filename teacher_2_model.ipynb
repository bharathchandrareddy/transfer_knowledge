{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # generating random spectrograms and saving them as .png files\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "\n",
    "# # Directory to save generated spectrograms\n",
    "# output_dir = \"C:\\\\Users\\\\PC\\\\Desktop\\\\lisnen_data\\\\noise\\\\noise_spectrograms\"\n",
    "# os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# # Function to generate random spectrograms\n",
    "# def generate_random_spectrogram(width=227, height=227, channels=3, num_spectrograms=100):\n",
    "#     for i in range(num_spectrograms):\n",
    "#         # Generate random pixel values\n",
    "#         random_spectrogram = np.random.rand(height, width, channels)\n",
    "        \n",
    "#         # Save the spectrogram as an image\n",
    "#         plt.imsave(os.path.join(output_dir, f\"spectrogram_{i}.png\"), random_spectrogram)\n",
    "\n",
    "# # Generate 100 random spectrograms\n",
    "# generate_random_spectrogram(num_spectrograms=100)\n",
    "\n",
    "# print(f\"Generated 10 random spectrograms of size 227x227 with 3 channels in the directory: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import os\n",
    "\n",
    "# def generate_gaussian_noise_spectrogram(width=227, height=227, channels=3, mean=0, std=0.1, num_spectrograms=100):\n",
    "\n",
    "#     for i in range(num_spectrograms):\n",
    "#         # Generate Gaussian noise\n",
    "#         noise = np.random.normal(mean, std, (height, width, channels))\n",
    "        \n",
    "#         # Normalize the noise to the range [0, 1]\n",
    "#         noise_min = np.min(noise)\n",
    "#         noise_max = np.max(noise)\n",
    "#         noise_normalized = (noise - noise_min) / (noise_max - noise_min)\n",
    "\n",
    "#         # Save the normalized noise spectrogram\n",
    "#         plt.imsave(os.path.join(output_dir, f\"gauss_noise_{i}.png\"), noise_normalized)\n",
    "\n",
    "# # Generate 10 Gaussian noise spectrograms as an example\n",
    "# generate_gaussian_noise_spectrogram(num_spectrograms=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.signal import welch\n",
    "\n",
    "# def generate_pink_noise_spectrogram(width=227, height=227, channels=3, num_spectrograms=100):\n",
    "#     for i in range(num_spectrograms):\n",
    "#         # Generate pink noise\n",
    "#         noise = np.random.randn(height, width, channels)\n",
    "        \n",
    "#         # Apply Fourier transform to get the frequency domain representation\n",
    "#         f_transform = np.fft.fftn(noise)\n",
    "        \n",
    "#         # Create a pink noise filter in the frequency domain\n",
    "#         freqs = np.fft.fftfreq(height, d=1.0/height)\n",
    "#         freqs = np.fft.fftshift(freqs)\n",
    "#         pink_filter = np.sqrt(1.0 / (freqs**2 + 1e-6))  # 1e-6 to avoid division by zero\n",
    "        \n",
    "#         # Apply the pink noise filter\n",
    "#         pink_transform = f_transform * pink_filter[:, None, None]\n",
    "        \n",
    "#         # Convert back to time domain\n",
    "#         pink_noise = np.fft.ifftn(pink_transform).real\n",
    "        \n",
    "#         # Normalize the noise to be in the range [0, 1]\n",
    "#         pink_noise = (pink_noise - np.min(pink_noise)) / (np.max(pink_noise) - np.min(pink_noise))\n",
    "\n",
    "#         # Save the normalized pink noise spectrogram\n",
    "#         plt.imsave(os.path.join(output_dir, f\"pink_noise_spectrogram_{i}.png\"), pink_noise)\n",
    "\n",
    "# # Generate 10 pink noise spectrograms as an example\n",
    "# generate_pink_noise_spectrogram(num_spectrograms=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'C:\\\\Users\\\\PC\\\\Desktop\\\\lisnen_data\\\\noise'\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Load dataset\n",
    "full_dataset = ImageFolder(root=base_dir, transform=data_transforms['train'])\n",
    "\n",
    "# Split dataset\n",
    "indices = list(range(len(full_dataset)))\n",
    "train_indices, temp_indices = train_test_split(indices, test_size=0.2, stratify=full_dataset.targets)\n",
    "val_indices, test_indices = train_test_split(temp_indices, test_size=0.5, stratify=[full_dataset.targets[i] for i in temp_indices])\n",
    "\n",
    "# Create subsets\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "val_dataset = Subset(full_dataset, val_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\anaconda3\\envs\\kd\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\anaconda3\\envs\\kd\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained ResNet-50 model\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# Modify the final fully connected layer to output 4 classes\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 4)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 0/9: 100%|██████████| 16/16 [00:04<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0806 Acc: 0.9754 Precision: 0.9765 Recall: 0.9754 F1 Score: 0.9754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 0/9: 100%|██████████| 2/2 [00:00<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0001 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 1/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 1/9: 100%|██████████| 16/16 [00:03<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0003 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 1/9: 100%|██████████| 2/2 [00:00<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0008 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 2/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 2/9: 100%|██████████| 16/16 [00:03<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0001 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 2/9: 100%|██████████| 2/2 [00:00<00:00,  8.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 3/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 3/9: 100%|██████████| 16/16 [00:03<00:00,  4.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0001 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 3/9: 100%|██████████| 2/2 [00:00<00:00,  7.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 4/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 4/9: 100%|██████████| 16/16 [00:03<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 4/9: 100%|██████████| 2/2 [00:00<00:00,  8.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 5/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 5/9: 100%|██████████| 16/16 [00:03<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 5/9: 100%|██████████| 2/2 [00:00<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 6/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 6/9: 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 6/9: 100%|██████████| 2/2 [00:00<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 7/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 7/9: 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 7/9: 100%|██████████| 2/2 [00:00<00:00,  8.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 8/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 8/9: 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 8/9: 100%|██████████| 2/2 [00:00<00:00,  8.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n",
      "Epoch 9/9\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train 9/9: 100%|██████████| 16/16 [00:03<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "val 9/9: 100%|██████████| 2/2 [00:00<00:00,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.0000 Acc: 1.0000 Precision: 1.0000 Recall: 1.0000 F1 Score: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Training function with progress bar and metric tracking\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, num_epochs=10):\n",
    "    train_acc_history = []\n",
    "    val_acc_history = []\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    \n",
    "    train_precision_history = []\n",
    "    val_precision_history = []\n",
    "    train_recall_history = []\n",
    "    val_recall_history = []\n",
    "    train_f1_history = []\n",
    "    val_f1_history = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "                dataloader = train_loader\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "                dataloader = val_loader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "\n",
    "            # Iterate over data\n",
    "            for inputs, labels in tqdm(dataloader, desc=f'{phase} {epoch}/{num_epochs - 1}'):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "            epoch_precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "            epoch_recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "            epoch_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} Precision: {epoch_precision:.4f} Recall: {epoch_recall:.4f} F1 Score: {epoch_f1:.4f}')\n",
    "\n",
    "            # Save the metrics\n",
    "            if phase == 'train':\n",
    "                train_loss_history.append(epoch_loss)\n",
    "                train_acc_history.append(epoch_acc)\n",
    "                train_precision_history.append(epoch_precision)\n",
    "                train_recall_history.append(epoch_recall)\n",
    "                train_f1_history.append(epoch_f1)\n",
    "            else:\n",
    "                val_loss_history.append(epoch_loss)\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                val_precision_history.append(epoch_precision)\n",
    "                val_recall_history.append(epoch_recall)\n",
    "                val_f1_history.append(epoch_f1)\n",
    "\n",
    "    return model, train_loss_history, val_loss_history, train_acc_history, val_acc_history, train_precision_history, val_precision_history, train_recall_history, val_recall_history, train_f1_history, val_f1_history\n",
    "\n",
    "# Train the model\n",
    "model, train_loss_history, val_loss_history, train_acc_history, val_acc_history, train_precision_history, val_precision_history, train_recall_history, val_recall_history, train_f1_history, val_f1_history = train_model(\n",
    "    model, criterion, optimizer, train_loader, val_loader, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:\\\\Users\\\\PC\\\\Desktop\\\\sample_projects\\\\transfer_knowledge\\\\models\\\\resnet_50_noise.pth'\n",
    "torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 1.0000\n",
      "Test Precision: 1.0000\n",
      "Test Recall: 1.0000\n",
      "Test F1 Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, dataloader, class_names):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    running_corrects = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    wrong_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            # Collect wrong predictions\n",
    "            wrong_indices = np.where(preds.cpu().numpy() != labels.cpu().numpy())[0]\n",
    "            for idx in wrong_indices:\n",
    "                wrong_predictions.append((inputs.cpu()[idx], preds.cpu().numpy()[idx], labels.cpu().numpy()[idx]))\n",
    "\n",
    "    accuracy = running_corrects.double() / len(dataloader.dataset)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "    print(f'Test Precision: {precision:.4f}')\n",
    "    print(f'Test Recall: {recall:.4f}')\n",
    "    print(f'Test F1 Score: {f1:.4f}')\n",
    "    \n",
    "    return wrong_predictions,all_labels,all_preds\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "class_names = ['noise','not noise']\n",
    "wrong_predictions = evaluate_model(model, test_loader, class_names)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing with the generated noisy data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
