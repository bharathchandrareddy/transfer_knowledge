{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets,transforms\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])\n",
    "])\n",
    "train_dataset = datasets.CIFAR10(root='./data',train=True,download=True,transform=data_transforms)\n",
    "test_dataset = datasets.CIFAR10(root='./data',train=False,download=True,transform=data_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the dataloaders for training and test\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,batch_size=32,shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the teacher model\n",
    "class Teacher_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Teacher_model,self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3,128,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(64,64,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,32,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        )\n",
    "        self.classfier = nn.Sequential(\n",
    "            nn.Linear(2048,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.layers(x)\n",
    "        x=torch.flatten(x,1)\n",
    "        x = self.classfier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class student_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(student_model,self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(3,16,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16,16,kernel_size=3,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),  \n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256,10)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x= self.layers(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "def train(model,train_dataloader,epochs,learning_rate,device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(),lr = learning_rate)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs,labels in train_dataloader:\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'epoch {epoch+1}/{epochs},loss={running_loss/len(train_dataloader)}')\n",
    "\n",
    "\n",
    "def test(model,test_dataloader,device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "teacher = Teacher_model()\n",
    "student = student_model()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(teacher, train_dataloader, epochs=10, learning_rate=0.001, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 73.06%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy_deep = test(teacher, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10,loss=1.3500913418185916\n",
      "epoch 2/10,loss=1.010557404025121\n",
      "epoch 3/10,loss=0.873339850953658\n",
      "epoch 4/10,loss=0.7763097844517391\n",
      "epoch 5/10,loss=0.6941467424805776\n",
      "epoch 6/10,loss=0.6254208700174867\n",
      "epoch 7/10,loss=0.5580854325037466\n",
      "epoch 8/10,loss=0.4969942342592445\n",
      "epoch 9/10,loss=0.4504838226052026\n",
      "epoch 10/10,loss=0.40440677486298104\n",
      "Test Accuracy: 69.26%\n"
     ]
    }
   ],
   "source": [
    "train(student, train_dataloader, epochs=10, learning_rate=0.001, device=device)\n",
    "test_accuracy_light_ce = test(student, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy for teacher :73.06%\n",
      "test accuracy fot student :69.26%\n"
     ]
    }
   ],
   "source": [
    "print(f'test_accuracy for teacher :{test_accuracy_deep:.2f}%')\n",
    "print(f'test accuracy fot student :{test_accuracy_light_ce:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to implement the teacher-student network we need few more parameters to be incorporated.\n",
    "#t= temperature (it controls how smooth the output is distributed)\n",
    "#soft_traget_loss_weight = A weight assigned to extra objective we're about to include\n",
    "#ce_loss_weight = A weight assigned to cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10,loss = 0.919714184045334\n",
      "epoch 2/10,loss = 0.8160603245862081\n",
      "epoch 3/10,loss = 0.7886000238239803\n",
      "epoch 4/10,loss = 0.7687715685146402\n",
      "epoch 5/10,loss = 0.7494939404729842\n",
      "epoch 6/10,loss = 0.7359033011886758\n",
      "epoch 7/10,loss = 0.720445447828399\n",
      "epoch 8/10,loss = 0.7077185597010934\n",
      "epoch 9/10,loss = 0.6964009245541792\n",
      "epoch 10/10,loss = 0.6875427604408044\n",
      "Test Accuracy: 69.37%\n"
     ]
    }
   ],
   "source": [
    "def train_kd(teacher,student,train_dataloader,T,epochs,learning_rate,device,soft_target_loss_weight,ce_loss_weight):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student.parameters(),lr=learning_rate)\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs,labels in train_dataloader:\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward method with teacher model\n",
    "            with torch.no_grad(): #we donot need to save gradients of teacher\n",
    "                teacher_logits = teacher(inputs)\n",
    "            student_logits = student(inputs)\n",
    "            #softening the distributions\n",
    "            soft_targets = nn.functional.softmax(teacher_logits/T,dim=1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits/T, dim= -1)\n",
    "            #distillation loss\n",
    "            distillation_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob) / soft_prob.size()[0]*(T**2))\n",
    "            #true label loss\n",
    "            label_loss = ce_loss(student_logits,labels)\n",
    "\n",
    "            #weighted sum of two losses\n",
    "            loss = distillation_loss * soft_target_loss_weight + ce_loss_weight*label_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "\n",
    "        print(f'epoch {epoch+1}/{epochs},loss = {running_loss / len(train_dataloader)}')\n",
    "\n",
    "train_kd(teacher,student,train_dataloader,T=2,epochs=10,learning_rate=0.001,device=device,soft_target_loss_weight=0.25,ce_loss_weight=0.75)\n",
    "test_accuracy_light_ce_kd = test(student,test_dataloader,device)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy for student model with kd 69.37% \n"
     ]
    }
   ],
   "source": [
    "print(f'test_accuracy for student model with kd {test_accuracy_light_ce_kd :.2f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fine tuning resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\.conda\\envs\\hydra\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\PC\\.conda\\envs\\hydra\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet_model = models.resnet50(pretrained = True,progress=True)\n",
    "\n",
    "#replace final fully connected layer for 10 output neurons\n",
    "\n",
    "num_features = resnet_model.fc.in_features\n",
    "num_classes = 10\n",
    "resnet_model.fc = nn.Linear(num_features,num_classes)\n",
    "model = resnet_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm  # Ensure tqdm is imported\n",
    "\n",
    "def finetune_resnet(resnet_model, train_dataloader, epochs=10):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(resnet_model.parameters(), lr=0.001)\n",
    "    resnet_model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        # tqdm for the inner loop to show progress within each epoch\n",
    "        for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = resnet_model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Print the average loss for this epoch\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_dataloader):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_resnet(resnet_model,test_dataloader):\n",
    "    resnet_model.eval()\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images,labels in test_dataloader:\n",
    "            images,labels = images.to(device),labels.to(device)\n",
    "            #forward pass\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            total +=labels.size(0)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "    \n",
    "    print(f'accuracy of resnet model on test data {100 *correct/total :.2f}%')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1563/1563 [17:42<00:00,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.2167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1563/1563 [18:41<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.8796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1563/1563 [19:03<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1563/1563 [19:19<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1563/1563 [19:25<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.5423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1563/1563 [19:38<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1563/1563 [19:49<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.4156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1563/1563 [19:55<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1563/1563 [19:56<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.2734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1563/1563 [20:09<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.2703\n",
      "accuracy of resnet model on test data 79.25%\n"
     ]
    }
   ],
   "source": [
    "finetune_resnet(resnet_model,train_dataloader,epochs=10)\n",
    "test_resnet(resnet_model,test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using resnet50 as teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10:   0%|          | 0/1563 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1563/1563 [03:06<00:00,  8.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10,loss = 0.6793455219162021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1563/1563 [03:05<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/10,loss = 0.6676746448948836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1563/1563 [03:04<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/10,loss = 0.6594219421699729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1563/1563 [03:04<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/10,loss = 0.653477133655121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1563/1563 [03:05<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/10,loss = 0.648380565742461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1563/1563 [03:04<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/10,loss = 0.6424061305921046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1563/1563 [03:04<00:00,  8.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/10,loss = 0.6374071494021327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1563/1563 [03:05<00:00,  8.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/10,loss = 0.6329485592518719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1563/1563 [03:04<00:00,  8.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/10,loss = 0.6283573880076637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1563/1563 [03:04<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/10,loss = 0.6240302789539233\n",
      "Test Accuracy: 67.61%\n"
     ]
    }
   ],
   "source": [
    "def train_resnet_cnn(teacher=resnet_model,student=student,train_dataloader=train_dataloader,T=2,epochs=10,learning_rate=0.001,device=device,soft_target_loss_weight=0.25,ce_loss_weight=0.75):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student.parameters(),lr=learning_rate)\n",
    "    teacher.eval()\n",
    "    student.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward method with teacher model\n",
    "            with torch.no_grad(): #we donot need to save gradients of teacher\n",
    "                teacher_logits = teacher(inputs)\n",
    "            student_logits = student(inputs)\n",
    "            #softening the distributions\n",
    "            soft_targets = nn.functional.softmax(teacher_logits/T,dim=1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits/T, dim= -1)\n",
    "            #distillation loss\n",
    "            distillation_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob) / soft_prob.size()[0]*(T**2))\n",
    "            #true label loss\n",
    "            label_loss = ce_loss(student_logits,labels)\n",
    "\n",
    "            #weighted sum of two losses\n",
    "            loss = distillation_loss * soft_target_loss_weight + ce_loss_weight*label_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "\n",
    "        print(f'epoch {epoch+1}/{epochs},loss = {running_loss / len(train_dataloader)}')\n",
    "\n",
    "train_resnet_cnn(teacher,student,train_dataloader,T=2,epochs=10,learning_rate=0.001,device=device,soft_target_loss_weight=0.25,ce_loss_weight=0.75)\n",
    "test_accuracy_light_ce_kd = test(student,test_dataloader,device)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 1563/1563 [07:21<00:00,  3.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10,loss = 0.3631158641379229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: 100%|██████████| 1563/1563 [07:03<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/10,loss = 0.35228893229462593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 1563/1563 [07:02<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/10,loss = 0.3474642373740635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 1563/1563 [07:06<00:00,  3.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/10,loss = 0.344817390702355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: 100%|██████████| 1563/1563 [07:26<00:00,  3.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/10,loss = 0.33911166408278587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: 100%|██████████| 1563/1563 [12:52<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/10,loss = 0.3359857910120251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 1563/1563 [07:12<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/10,loss = 0.33080340293608484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 1563/1563 [06:53<00:00,  3.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/10,loss = 0.33205147951326536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 1563/1563 [06:54<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/10,loss = 0.3265010122965332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: 100%|██████████| 1563/1563 [06:55<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/10,loss = 0.32474255322532936\n",
      "Test Accuracy: 67.66%\n"
     ]
    }
   ],
   "source": [
    "def train_2teacher_model(teacher1,teacher2,student,train_dataloader,T=2,epochs=10,learning_rate=0.001,device=device,soft_target_loss_weight=0.5,ce_loss_weight=0.5):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student.parameters(),lr=learning_rate)\n",
    "    teacher1.eval()\n",
    "    teacher2.eval()\n",
    "    student.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "            inputs,labels = inputs.to(device),labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #forward method with teacher model\n",
    "            with torch.no_grad(): #we donot need to save gradients of teacher\n",
    "                teacher1_logits = resnet_model(inputs)\n",
    "                teacher2_logits = teacher(inputs)\n",
    "            student_logits = student(inputs)\n",
    "            #softening the distributions\n",
    "            soft_targets1 = nn.functional.softmax(teacher1_logits/T,dim=1)\n",
    "            soft_targets2 = nn.functional.softmax(teacher2_logits/T,dim=1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits/T, dim= -1)\n",
    "            soft_targets = (soft_targets1 + soft_targets2)/2\n",
    "            #distillation loss\n",
    "            distillation_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob) / soft_prob.size()[0]*(T**2))\n",
    "            #true label loss\n",
    "            label_loss = ce_loss(student_logits,labels)\n",
    "\n",
    "            #weighted sum of two losses\n",
    "            loss = distillation_loss * soft_target_loss_weight + ce_loss_weight*label_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss +=loss.item()\n",
    "\n",
    "        print(f'epoch {epoch+1}/{epochs},loss = {running_loss / len(train_dataloader)}')\n",
    "\n",
    "train_2teacher_model(teacher1=resnet_model,teacher2=teacher,student=student,train_dataloader=train_dataloader,T=2,epochs=10,learning_rate=0.001,device=device,soft_target_loss_weight=0.25,ce_loss_weight=0.75)\n",
    "test_accuracy_light_ce_kd = test(student,test_dataloader,device)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of student_model(\n",
       "  (layers): Sequential(\n",
       "    (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=10, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
